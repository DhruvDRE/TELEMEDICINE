{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement cgi (from versions: none)\n",
      "ERROR: No matching distribution found for cgi\n",
      "WARNING: You are using pip version 20.1; however, version 21.0.1 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\hp\\Anaconda3\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "pip install cgi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ha():\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "    import seaborn as sns\n",
    "\n",
    "\n",
    "    # In[2]:\n",
    "\n",
    "\n",
    "    df=pd.read_csv('heart2.csv')#heart UCI\n",
    "    df\n",
    "\n",
    "\n",
    "    # In[3]:\n",
    "\n",
    "\n",
    "    y=df['target']# target\n",
    "    x=df.drop(['target'],axis=1)#feature\n",
    "\n",
    "\n",
    "    # In[4]:\n",
    "\n",
    "\n",
    "    x.shape\n",
    "\n",
    "\n",
    "    # In[5]:\n",
    "\n",
    "\n",
    "    y.shape\n",
    "\n",
    "\n",
    "    # In[6]:\n",
    "\n",
    "\n",
    "    type(x)\n",
    "\n",
    "\n",
    "    # In[7]:\n",
    "\n",
    "\n",
    "    type(y)\n",
    "\n",
    "\n",
    "    # In[8]:\n",
    "\n",
    "\n",
    "    df.describe()# exploring the data\n",
    "\n",
    "\n",
    "    # In[9]:\n",
    "\n",
    "\n",
    "    # Machine learning model\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    lr=LogisticRegression()\n",
    "    lr.fit(x,y)\n",
    "\n",
    "\n",
    "    # In[10]:\n",
    "\n",
    "\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    xtr,xts,ytr,yts=train_test_split(x,y,test_size=0.25)\n",
    "\n",
    "\n",
    "    # In[11]:\n",
    "\n",
    "\n",
    "    xtr.shape\n",
    "\n",
    "\n",
    "    # In[12]:\n",
    "\n",
    "\n",
    "    xts.shape\n",
    "\n",
    "\n",
    "    # In[13]:\n",
    "\n",
    "\n",
    "    lr.fit(xtr,ytr)#training on new train data\n",
    "    yp=lr.predict(xts)#predicting new data\n",
    "    lr.score(xts,yts)\n",
    "\n",
    "\n",
    "    # In[14]:\n",
    "\n",
    "\n",
    "    # Adding cross Validation\n",
    "    from sklearn.model_selection import cross_val_score\n",
    "    cv_score=cross_val_score(lr,x,y,cv=5)\n",
    "    np.mean(cv_score)\n",
    "\n",
    "\n",
    "    # In[15]:\n",
    "\n",
    "\n",
    "    # Confusion matrix & Classification Model\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "    # In[16]:\n",
    "\n",
    "\n",
    "    cm=confusion_matrix(yts,yp)# to check original outcome to our models prediction\n",
    "    #print(cm)\n",
    "    sns.heatmap(cm,annot=True)\n",
    "\n",
    "\n",
    "    # In[20]:\n",
    "\n",
    "\n",
    "    #print(classification_report(yts,yp))\n",
    "\n",
    "\n",
    "    # In[17]:\n",
    "\n",
    "\n",
    "    y_pred=lr.predict(xts)# prediction of data fit/trained from data on x test set\n",
    "    cm=confusion_matrix(yts,y_pred)#creating a confusion matrix of test set of y and predicted y set to s=check the values were true\n",
    "    sns.heatmap(cm,annot=True)\n",
    "\n",
    "\n",
    "    # # Using Random Forest Classifier\n",
    "\n",
    "    # In[18]:\n",
    "\n",
    "\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    dec=RandomForestClassifier(n_estimators=50)#hyper parameter training\n",
    "    dec.fit(xtr,ytr)\n",
    "    #Evaluate the dec tree\n",
    "    print(\"Accuracy:\",dec.score(xts,yts))\n",
    "    yp1=dec.predict(xts)\n",
    "\n",
    "\n",
    "    # In[19]:\n",
    "\n",
    "\n",
    "    #ca=confusion_matrix(yts,yp1)\n",
    "    #sns.heatmap(ca,annot=True)\n",
    "\n",
    "\n",
    "    # In[18]:\n",
    "\n",
    "\n",
    "    # for any new prediction`\n",
    "\n",
    "    #x=input()\n",
    "    yp1=lr.predict([[68,1,0,144,193,1,1,141,0,3.4,1,2,3]])#lr.predict(xts)\n",
    "    if yp1==0:\n",
    "        print(\"Low Chances Of Heart ATTACK\")\n",
    "    else:\n",
    "        print(\"Higher Chances Of Heart ATTACK\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0            6      148             72             35        0  33.6   \n",
       "1            1       85             66             29        0  26.6   \n",
       "2            8      183             64              0        0  23.3   \n",
       "3            1       89             66             23       94  28.1   \n",
       "4            0      137             40             35      168  43.1   \n",
       "\n",
       "   DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                     0.627   50        1  \n",
       "1                     0.351   31        0  \n",
       "2                     0.672   32        1  \n",
       "3                     0.167   21        0  \n",
       "4                     2.288   33        1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df=pd.read_csv('diabetes.csv')#heart UCI\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cav():\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    import matplotlib.pyplot as plt\n",
    "    import seaborn as sns\n",
    "\n",
    "\n",
    "    # In[2]:\n",
    "\n",
    "\n",
    "    df=pd.read_csv('cardio_train.csv')\n",
    "    df\n",
    "\n",
    "\n",
    "    # In[3]:\n",
    "\n",
    "\n",
    "    df=df.drop(['id','age','gender','height'],axis=1)\n",
    "\n",
    "\n",
    "    # In[4]:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # In[5]:\n",
    "\n",
    "\n",
    "    y=df['cardio']\n",
    "    x=df.drop(['cardio'],axis=1)\n",
    "    \n",
    "\n",
    "\n",
    "    # In[6]:\n",
    "\n",
    "\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    lr=LogisticRegression()\n",
    "    lr.fit(x,y)\n",
    "\n",
    "\n",
    "    # In[7]:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # In[31]:\n",
    "\n",
    "\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    xtr,xts,ytr,yts=train_test_split(x,y,test_size=0.25)\n",
    "\n",
    "\n",
    "    # In[9]:\n",
    "\n",
    "\n",
    "   \n",
    "\n",
    "\n",
    "    # In[22]:\n",
    "\n",
    "\n",
    "    lr.fit(xtr,ytr)\n",
    "\n",
    "\n",
    "    # In[23]:\n",
    "\n",
    "\n",
    "    yp=lr.predict(xts)\n",
    "\n",
    "\n",
    "    # In[24]:\n",
    "\n",
    "\n",
    "    lr.score(xts,yts)\n",
    "\n",
    "\n",
    "    # In[25]:\n",
    "\n",
    "\n",
    "    # Adding cross Validation\n",
    "    #from sklearn.model_selection import cross_val_score\n",
    "    #cv_score=cross_val_score(lr,x,y,cv=5)\n",
    "    #np.mean(cv_score)\n",
    "\n",
    "\n",
    "    # In[26]:\n",
    "\n",
    "\n",
    "    # Confusion matrix & Classification Model\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "    # In[27]:\n",
    "\n",
    "\n",
    "    #confusion_matrix(yts,yp)\n",
    "\n",
    "\n",
    "    # In[28]:\n",
    "\n",
    "\n",
    "    \n",
    "    #print(classification_report(yts,yp))\n",
    "\n",
    "\n",
    "    # In[29]:\n",
    "\n",
    "\n",
    "    #y_pred=lr.predict(xts)# prediction of data fit/trained from data on x test set\n",
    "    #cm=confusion_matrix(yts,y_pred)#creating a confusion matrix of test set of y and predicted y set to s=check the values were true\n",
    "    #sns.heatmap(cm,annot=True)\n",
    "\n",
    "\n",
    "    # # Using Random Forest Classifier\n",
    "    # \n",
    "\n",
    "    # In[32]:\n",
    "\n",
    "\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    dec=RandomForestClassifier(n_estimators=50)#hyper parameter training\n",
    "    dec.fit(xtr,ytr)\n",
    "    #Evaluate the dec tree\n",
    "    print(\"Accuracy :\",dec.score(xts,yts))\n",
    "    yp1=dec.predict(xts)\n",
    "\n",
    "\n",
    "    # In[20]:\n",
    "\n",
    "\n",
    "    #ca=confusion_matrix(yts,yp1)\n",
    "    #sns.heatmap(ca,annot=True)\n",
    "\n",
    "\n",
    "    # In[98]:\n",
    "\n",
    "\n",
    "    yp1=lr.predict([[62.0,110,80,1,1,0,0,1]])#lr.predict(xts)\n",
    "    if yp1==0:\n",
    "        print(\"Low Chances Of Cardio Vascular Disorder\")\n",
    "    else:\n",
    "        print(\"Higher Chances Of Cardio Vascular Disorder\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def can():\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "    import seaborn as sns\n",
    "\n",
    "\n",
    "    # In[2]:\n",
    "\n",
    "\n",
    "    df=pd.read_csv('breast_cancer_data.csv')\n",
    "    #df.drop([''],axis=1)\n",
    "    df\n",
    "\n",
    "\n",
    "    # In[3]:\n",
    "\n",
    "\n",
    "    df=df.drop(['id','Unnamed: 32'],axis=1)\n",
    "\n",
    "\n",
    "    # In[4]:\n",
    "\n",
    "\n",
    "    df['diagnosis']=df['diagnosis'].map({'M':0,'B':1})# to replace the M, B to the 0,1\n",
    "    df.diagnosis.unique()\n",
    "\n",
    "\n",
    "    # In[5]:\n",
    "\n",
    "\n",
    "    y=df['diagnosis']# target\n",
    "    x=df.drop(['diagnosis'],axis=1)#feature\n",
    "\n",
    "\n",
    "    # In[8]:\n",
    "\n",
    "\n",
    "    x.shape\n",
    "\n",
    "\n",
    "    # In[7]:\n",
    "\n",
    "\n",
    "    y.shape\n",
    "\n",
    "\n",
    "    # In[9]:\n",
    "\n",
    "\n",
    "    type(x)\n",
    "\n",
    "\n",
    "    # In[10]:\n",
    "\n",
    "\n",
    "    type(y)\n",
    "\n",
    "\n",
    "    # In[11]:\n",
    "\n",
    "\n",
    "    df.describe()# exploring the data\n",
    "\n",
    "\n",
    "    # In[12]:\n",
    "\n",
    "\n",
    "    # Machine learning model\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    lr=LogisticRegression()\n",
    "    lr.fit(x,y)\n",
    "\n",
    "\n",
    "    # In[24]:\n",
    "\n",
    "\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    xtr,xts,ytr,yts=train_test_split(x,y,test_size=0.25,stratify=y)\n",
    "\n",
    "\n",
    "    # In[25]:\n",
    "\n",
    "\n",
    "    xtr.shape\n",
    "\n",
    "\n",
    "    # In[26]:\n",
    "\n",
    "\n",
    "    xts.shape\n",
    "\n",
    "\n",
    "    # In[27]:\n",
    "\n",
    "\n",
    "    lr.fit(xtr,ytr)#training on new train data\n",
    "    yp=lr.predict(xts)#predicting new data\n",
    "    lr.score(xts,yts)\n",
    "\n",
    "\n",
    "    # In[28]:\n",
    "\n",
    "\n",
    "    # Adding cross Validation\n",
    "    from sklearn.model_selection import cross_val_score\n",
    "    cv_score=cross_val_score(lr,x,y,cv=5)\n",
    "    np.mean(cv_score)\n",
    "\n",
    "\n",
    "    # In[29]:\n",
    "\n",
    "\n",
    "    # Confusion matrix & Classification Model\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "    # In[30]:\n",
    "\n",
    "\n",
    "\n",
    "    cm=confusion_matrix(yts,yp)# to check original outcome to our models prediction\n",
    "    #print(cm)\n",
    "    #sns.heatmap(cm,annot=True)\n",
    "\n",
    "\n",
    "    # In[31]:\n",
    "\n",
    "\n",
    "    #print(classification_report(yts,yp))\n",
    "\n",
    "\n",
    "    # #  Using Random Forest Classifier\n",
    "\n",
    "    # In[32]:\n",
    "\n",
    "\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    dec=RandomForestClassifier(n_estimators=50)#hyper parameter training\n",
    "    dec.fit(xtr,ytr)\n",
    "    #Evaluate the dec tree\n",
    "    print(\"Accuracy :\",dec.score(xts,yts))\n",
    "    yp1=dec.predict(xts)\n",
    "\n",
    "\n",
    "    # In[33]:\n",
    "\n",
    "\n",
    "    #ca=confusion_matrix(yts,yp1)\n",
    "    #sns.heatmap(ca,annot=True)\n",
    "\n",
    "\n",
    "    # In[21]:\n",
    "\n",
    "\n",
    "    # for any new prediction\n",
    "    yp1=lr.predict([[17.99,10.38,122.8,1001,0.1184,0.2776,0.3001,0.1471,0.2419,0.07871,1.095,0.9053,8.589,153.4,0.006399,0.04904,0.05373,0.01587,0.03003,0.006193,25.38,17.33,184.6,2019,0.1622,0.6656,0.7119,0.2654,0.4601,0.1189]])#lr.predict(xts)\n",
    "    if yp1==0:\n",
    "        print(\"malignant\")\n",
    "    else:\n",
    "        print(\"benign\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\hp\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\hp\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\hp\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\hp\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\hp\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\hp\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\hp\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\hp\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.958041958041958\n",
      "malignant\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\hp\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\hp\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\hp\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\hp\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7894736842105263\n",
      "Low Chances Of Heart ATTACK\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "can()\n",
    "ha()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dia():\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "    import seaborn as sns\n",
    "\n",
    "\n",
    "    # In[4]:\n",
    "\n",
    "\n",
    "    df=pd.read_csv('diabetes.csv')\n",
    "    df\n",
    "\n",
    "\n",
    "    # In[7]:\n",
    "\n",
    "\n",
    "    df.head()\n",
    "\n",
    "\n",
    "    # In[8]:\n",
    "\n",
    "\n",
    "    y=df['Outcome']# target value \n",
    "    x=df.drop(['Outcome'],axis=1)#feature\n",
    "    x.shape\n",
    "    y.shape\n",
    "\n",
    "\n",
    "    # In[9]:\n",
    "\n",
    "\n",
    "    type(x)\n",
    "\n",
    "\n",
    "    # In[10]:\n",
    "\n",
    "\n",
    "    type(y)\n",
    "\n",
    "\n",
    "    # In[11]:\n",
    "\n",
    "\n",
    "    x.fillna(df.median(),inplace=True)#all the nan values are removed\n",
    "    x.isnull().sum()\n",
    "\n",
    "\n",
    "    # In[12]:\n",
    "\n",
    "\n",
    "    from sklearn.linear_model import LinearRegression\n",
    "    lr=LinearRegression() #instanstiation\n",
    "    lr.fit(x,y)#fitting / training the data\n",
    "\n",
    "\n",
    "    # In[13]:\n",
    "\n",
    "\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    xtr,xts,ytr,yts=train_test_split(x,y,test_size=0.25)\n",
    "\n",
    "\n",
    "    # In[14]:\n",
    "\n",
    "\n",
    "    xts.shape\n",
    "\n",
    "\n",
    "    # In[15]:\n",
    "\n",
    "\n",
    "    xtr.shape\n",
    "\n",
    "\n",
    "    # In[16]:\n",
    "\n",
    "\n",
    "    lr1=LinearRegression()\n",
    "    lr1.fit(xtr,ytr)# training on new train set\n",
    "    yp=lr1.predict(xts)# testing model on new test data\n",
    "\n",
    "\n",
    "    # In[17]:\n",
    "\n",
    "\n",
    "    lr1.score(xts,yts)\n",
    "\n",
    "\n",
    "    # #  Logistic Regression Model On Diabetes\n",
    "    # \n",
    "\n",
    "    # In[19]:\n",
    "\n",
    "\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    logr=LogisticRegression()\n",
    "    logr.fit(xtr,ytr)\n",
    "    #yp1=logr.predict([[3,100,63,25,80,28.2,1.23,29]])# \n",
    "    yp1=logr.predict(xts)\n",
    "    logr.score(xts,yts)\n",
    "\n",
    "\n",
    "    # In[ ]:\n",
    "\n",
    "\n",
    "    \"\"\"if yp1==0:\n",
    "        print(\"Not Diabetic\")\n",
    "    else:\n",
    "        print(\"Diabetic\")\"\"\"\n",
    "\n",
    "\n",
    "    # # Using Random FOrest classifier\n",
    "\n",
    "    # In[ ]:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # In[20]:\n",
    "\n",
    "\n",
    "    from sklearn.model_selection import cross_val_score\n",
    "    cv_score=cross_val_score(logr,x,y,cv=6)\n",
    "    np.mean(cv_score)\n",
    "\n",
    "\n",
    "    # In[21]:\n",
    "\n",
    "\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    dec=RandomForestClassifier(n_estimators=50)#hyper parameter training\n",
    "    dec.fit(xtr,ytr)\n",
    "    #Evaluate the dec tree\n",
    "    print(\"Accuracy:\",dec.score(xts,yts))\n",
    "    yp1=dec.predict(xts)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
